{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import dataloaders\n",
    "\n",
    "class Cifar10DataLoader:\n",
    "    def __init__(self, pickles_path, batch_size, preprocessing_method):\n",
    "        self.data = list()\n",
    "        self.labels = list()\n",
    "        self.batch_size = batch_size\n",
    "        self.read_batches(pickles_path)\n",
    "        self.num_calsses = int(self.labels.max() - self.labels.min() + 1)\n",
    "        \n",
    "        # Preprocessing Method\n",
    "        assert preprocessing_method.lower() in [\"normalized\", \"standardized\", \"no\"], \"Error!! Undefined preprocessing. Preprocessing method must be one of this elements: ['normalized', 'standardized', 'no']\"\n",
    "        self.preprocessing_method = preprocessing_method\n",
    "        \n",
    "        # Preprocessing Data\n",
    "        if self.preprocessing_method == \"normalized\":\n",
    "            # minimum of data\n",
    "            self.min = np.min(self.data)\n",
    "            \n",
    "            # maximum of data \n",
    "            self.max = np.max(self.data)\n",
    "            \n",
    "            # normalization\n",
    "            self.data = (self.data - self.min) / (self.max - self.min)\n",
    "            \n",
    "        elif self.preprocessing_method == \"standardized\":\n",
    "            # mean of data\n",
    "            self.mean = np.mean(self.data)\n",
    "            \n",
    "            # std of data\n",
    "            self.std = np.std(self.data)\n",
    "            \n",
    "            #standardized\n",
    "            self.data = (self.data - self.mean) / self.std\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def read_pickle(self, path):\n",
    "        with open (path, \"rb\") as file:\n",
    "            pickle_dict = pickle.load(file , encoding = \"latin1\")\n",
    "        return np.array(pickle_dict[\"labels\"]), pickle_dict[\"data\"]\n",
    "    \n",
    "    def read_batches(self, pickles_path):\n",
    "        \n",
    "        for path in pickles_path:\n",
    "            path_label, path_data = self.read_pickle(path)\n",
    "            self.data.append(path_data)\n",
    "            self.labels.append(path_label)\n",
    "            \n",
    "        self.data = np.concatenate(self.data).astype(np.float64)\n",
    "        self.labels = np.concatenate(self.labels).astype(int)\n",
    "        \n",
    "    def get_batch(self,ix):\n",
    "        start_ix = ix * self.batch_size\n",
    "        end_ix = (ix+1)* self.batch_size\n",
    "        if end_ix > self.data.shape[0]:\n",
    "            end_ix = self.data.shape[0]\n",
    "        \n",
    "        batch_data = self.data[start_ix :end_ix , :]\n",
    "        batch_labels = self.labels [ start_ix :end_ix ]\n",
    "        \n",
    "        one_hot_batch_labels = np.zeros((self.batch_size, self.num_calsses))\n",
    "        one_hot_batch_labels[np.arange(self.batch_size), batch_labels.astype(int)] = 1\n",
    "        \n",
    "        return batch_data , one_hot_batch_labels\n",
    "    \n",
    "    def get_num_batches(self):\n",
    "        num_data = self.data.shape[0]\n",
    "        return math.ceil(num_data / self.batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        \n",
    "    def read_batches(self, pickles_path):\n",
    "        \n",
    "        for path in pickles_path:\n",
    "            path_label, path_data = self.read_pickle(path)\n",
    "            self.data.append(path_data)\n",
    "            self.labels.append(path_label)\n",
    "            \n",
    "        self.data = np.concatenate(self.data).astype(np.float64)\n",
    "        self.labels = np.concatenate(self.labels).astype(np.float64)\n",
    "        \n",
    "            \n",
    "    def get_item(self, ix):\n",
    "        return self.data[ix,:],self.labels[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickles_path = [\n",
    "  \"./datasets/cifar10/data_batch_1\",\n",
    "  \"./datasets/cifar10/data_batch_2\",\n",
    "  \"./datasets/cifar10/data_batch_3\",\n",
    "  \"./datasets/cifar10/data_batch_4\",\n",
    "  \"./datasets/cifar10/data_batch_5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Cifar10DataLoader(\n",
    "    pickles_path = pickles_path,\n",
    "    batch_size = 2,\n",
    "    preprocessing_method = \"normalized\"\n",
    ")\n",
    "\n",
    "X , Y_target = data.get_batch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_target = np.array([6, 9])\n",
    "o = np.zeros((2, 10))\n",
    "o[np.arange(2), Y_target.astype(int)] = 1\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.zeros((4, 3))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[[0,0,1,2,2],[0,1,1,1,2]] = 1\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array([5])\n",
    "Y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
