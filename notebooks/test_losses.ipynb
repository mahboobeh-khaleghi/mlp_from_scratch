{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nets import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Loss:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def forward(self,y_out, y_target):\n",
    "        batch_size = y_out.shape[0]\n",
    "        return np.sum(\n",
    "            np.power(y_out-y_target ,2)\n",
    "        ) / batch_size\n",
    "    \n",
    "    def backward(self, y_out , y_target):\n",
    "        return np.multiply(2, y_out - y_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def forward(self, y_out , y_target):\n",
    "        batch_size = y_out.shape[0]\n",
    "        return np.sum(\n",
    "            np.multiply(y_target ,np.log(y_out))\n",
    "        ) / batch_size\n",
    "        \n",
    "    def backward(self,y_out , y_target):\n",
    "        return -np.divide(y_target , y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftmaxCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropy:\n",
    "    def __init__(self) -> None:\n",
    "        self.softmax_act = activations.Softmax()\n",
    "    \n",
    "    def forward(self, score , y_target):\n",
    "        y_out = self.softmax_act.forward(score)\n",
    "        ln_y_out = np.log (y_out)\n",
    "        loss = - np.sum (np.multiply(y_target,ln_y_out))\n",
    "        return loss / y_out.shape[0]\n",
    "    \n",
    "    def backward(self, score , y_target):\n",
    "        assert self.check_sum_y_target_one(y_target), \"Error!!! Sum of Y_target in every data must equals to one.\"\n",
    "        y_out = self.softmax_act.forward(score)\n",
    "        return y_out - y_target\n",
    "    \n",
    "    def check_sum_y_target_one(self, y_target):\n",
    "        batch_size = y_target.shape[0]\n",
    "        does_one = np.sum(y_target, axis=1) == np.ones(batch_size)\n",
    "        return np.sum(does_one) == batch_size\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target = np.array([\n",
    "    [0, 0.5, 0, 0.25, 0.25],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0]\n",
    "])\n",
    "\n",
    "batch_size = y_target.shape[0]\n",
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "does_one = np.sum(y_target, axis=1) == np.ones(batch_size)\n",
    "does_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(does_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(does_one) == batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
